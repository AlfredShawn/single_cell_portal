{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "\n",
    "# Plotly inline\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate graphs\n",
    "def parse_logs(filename_pairs_arr, hours=1):\n",
    "    \"\"\"\"Function to generate plotly graph of CellRanger Monitor Logs with CellRanger std_out Annotations\n",
    "    Inputs:\n",
    "        filename_pairs_arr: Array of usage monitoring logs and matching annotation logs in this format-\n",
    "            [[\"monitroig_log.log\",\"corresponding_std_out.txt\"], [\"monitroig_log2.log\",\"corresponding_std_out2.txt\"]]\n",
    "        hours: default length of x axis in hours\n",
    "    Outpus:\n",
    "        Plotly Graph of Maps: The Legend items are grouped by usage type, disk, core and mem. The title is the VM stats of the run.\n",
    "                             The CellRanger task names are outputted in the middle of the graph vertically at the time they occured.\n",
    "                             The xaxis starts at the time of the first task started, and is defaulted to have the range of hours input.\n",
    "    \"\"\"\n",
    "    # Collection Arrays\n",
    "    # Data: Plotly traces of line graphs of usages\n",
    "    data = []\n",
    "    # Start times of every task\n",
    "    earlys = []\n",
    "    # Cellranger Tasks\n",
    "    events = []\n",
    "    # Iterate through filename pairs and populate collection arrays\n",
    "    for filename_pair in filename_pairs_arr:\n",
    "        # monitoring log is first file\n",
    "        monitor = filename_pair[0]\n",
    "        # std out is second file\n",
    "        std = filename_pair[1]\n",
    "        # read std out file\n",
    "        with open(std) as b:\n",
    "            lines = b.readlines()\n",
    "        # parse through the std out file to get major task names\n",
    "        for line in lines:\n",
    "            # theres a bunch of meta output that we ignore like copyright info\n",
    "            # lines that matter have \"[runtime]\" in them, so get them\n",
    "            if \"[runtime]\" in line:\n",
    "                # split the line into components we want\n",
    "                # EXAMPLE LINE WE WANT\n",
    "                \"\"\"\"\n",
    "                2018-07-16 21:13:45 [runtime] (ready)           ID.HJCVJBGX5.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET\n",
    "                \"\"\"\n",
    "                lline_arr = line.strip().split()\n",
    "                # important tasks have '(ready)' after '[runtime]'\n",
    "                if lline_arr[3] == '(ready)':\n",
    "                    # parse date\n",
    "                    dt = parser.parse(' '.join(lline_arr[0:2]))\n",
    "                    # Get the event name, can be different formats, this should generally get all of them into right format though\n",
    "                    event_name = ''.join(lline_arr[4:]).split(\".\")[-1]\n",
    "                    # add formatted event [datetime, event_name] to collection\n",
    "                    events = events + [[dt, event_name]]       \n",
    "        # Open the monitor log and parse it\n",
    "        with open(monitor) as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Read Caps of Stats we monitor, each one is parsed and converted to float\n",
    "        cpu_cap = int(re.sub(\"[^$0-9.]\",\"\", [line for line in lines if 'CPU:' in line][0]))\n",
    "        mem_cap = float(re.sub(\"[^$0-9.]\",\"\", [line for line in lines if 'Total Memory:' in line][0]))\n",
    "        disk_cap = float(re.sub(\"[^$0-9.]\",\"\", [line for line in lines if 'Total Disk space:' in line][0]))\n",
    "\n",
    "        # Collections for plotly trace\n",
    "        # cpu usages\n",
    "        cpu = []\n",
    "        # mem usages\n",
    "        mem = []\n",
    "        # disk usages\n",
    "        disk = []\n",
    "        # measurement times\n",
    "        time = []\n",
    "        # parse through each line and add it to collection\n",
    "        # EXAMPLE MONITORING LINE GROUP\n",
    "        \"\"\"\"\n",
    "        [Tue Jul 17 04:14:59 UTC 2018]\n",
    "        * CPU usage: 8.1%\n",
    "        * Memory usage: 6%\n",
    "        * Disk usage: 57%\n",
    "        \"\"\"\n",
    "        for line in lines:\n",
    "            if 'CPU usage:' in line:\n",
    "                # if it's a cpu line parse to float and add to cpu collector\n",
    "                cpu = cpu + [float(re.sub(\"[^$0-9.]\",\"\", line))]\n",
    "            elif 'Memory usage:' in line:\n",
    "                # if it's a mem line parse to float and add to mem collector\n",
    "                mem = mem + [float(re.sub(\"[^$0-9.]\",\"\", line ))]\n",
    "            elif 'Disk usage:' in line:\n",
    "                # if it's a disk line parse to float and add to disk collector\n",
    "                disk = disk + [float(re.sub(\"[^$0-9.]\",\"\", line))]\n",
    "            elif '[' in line:\n",
    "                # if it's a time line parse to datetime object and add to time collector\n",
    "                time = time + [parser.parse(line.replace(\"[\", '').replace(\"]\", '').strip())]\n",
    "        # create a dataframe to make adding to plotly easier\n",
    "        df = pd.DataFrame(data={'cores': cpu, 'memory usage (GB)': mem, 'disk usage (GB)': disk, 'time':time})\n",
    "        # create the title- eg \"Usage: 64.0 Cores, 236.0 G Memory, 394.0 G Disk Space\" \n",
    "        title = \"Usage: \" + str(cpu_cap) + \" Cores, \" + str(mem_cap) + \" GB Memory, \" + str(disk_cap) + \" GB Disk Space\"  \n",
    "        # CPU usage trace (Note the legend group)\n",
    "        trace1 = go.Scatter(\n",
    "            x = df.time,\n",
    "            y = df['cores'],\n",
    "            name = monitor + ' core usage',\n",
    "            legendgroup =  'core usage',\n",
    "        )\n",
    "\n",
    "        # Memory Usage trace (Note the legend group)\n",
    "        trace2 = go.Scatter(\n",
    "            x = df.time,\n",
    "            y = df['memory usage (GB)'],\n",
    "            name = monitor + ' memory usage (GB)',\n",
    "            legendgroup =  'memory usage (GB)',\n",
    "        )\n",
    "\n",
    "        # Disk Usage trace (Note the legend group)\n",
    "        trace3 = go.Scatter(\n",
    "            x = df.time,\n",
    "            y = df['disk usage (GB)'],\n",
    "            name = monitor + ' disk usage (GB)',\n",
    "            legendgroup =  'disk usage (GB)',\n",
    "        )\n",
    "        \n",
    "        # Add to data collector for plotly\n",
    "        data = data + [trace1, trace2, trace3]\n",
    "        \n",
    "        # get the earliest time (aka start of task) and add it to early collector\n",
    "        earlys = earlys + [min(time)]\n",
    "    # TODO figure out a better way to make sure these annotations, which can be long, do not overlap\n",
    "    def height(num, x =40, maxh =60, by =10):\n",
    "        \"\"\"Generator to alternate heights of annotation labels\n",
    "            Inputs:\n",
    "                num: number of heights we want to output\n",
    "                minh: min height of annotation\n",
    "                maxh: max height of annotation\n",
    "                by: amount to increase height every time\n",
    "            Outputs:\n",
    "                Yields varying heights from minh, minh + by... maxh, minh, minh + by... \n",
    "        \"\"\"\n",
    "        n = 0\n",
    "        minh = 40\n",
    "        while n < num:\n",
    "            if minh == maxh:\n",
    "                yield x\n",
    "                minh = 40\n",
    "                n +=1 \n",
    "            yield minh\n",
    "            minh += by\n",
    "            n += 1\n",
    "    # get heights of annotations\n",
    "    heights = height(len(events))\n",
    "    # create annotations layout list\n",
    "    annotations = []\n",
    "    for event in sorted(events, key=lambda x : x[0]):\n",
    "        annotation = dict(x = event[0], y = next(heights), \n",
    "                                           xref = 'x', yref = 'y', text = event[1], \n",
    "                                           textangle = -45, showarrow = False)\n",
    "        annotations = annotations + [annotation]\n",
    "    # generate layout using collectors\n",
    "    layout = dict(title = title,\n",
    "                  xaxis = dict(title = 'Time', range = [min(earlys), min(earlys)+ timedelta(hours=hours)]),\n",
    "                  yaxis = dict(title = '% Usage', range = [0,100]),\n",
    "                 annotations = annotations)\n",
    "    # plot\n",
    "    iplot({'data':data, 'layout':layout})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
